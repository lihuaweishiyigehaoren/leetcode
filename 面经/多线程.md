#### 线程安全的栈

**序列化：**

```
在互斥量的保护下，同一时间内只有一个线程可以获得互斥锁，互斥量为了保护数据，显式的组织了线程对数据结构的并发访问，这被称为序列化
线程轮流访问被保护的数据,这其实是对数据进行串形的访问，而非并发
```

目的：如何提高并发能力：减少保护区域，减少序列化操作

```c++
struct empty_stack: std::exception
{
    const char* what() const throw() {
        return "empty stack!";
    }
};

template<typename T>
class threadsafe_stack
{
private:
    std::stack<T> data;
    mutable mutex m;
public:
    threadsafe_stack(){}

    threadsafe_stack(const threadsafe_stack& other)
    {
        lock_guard<mutex> lock(other.m);
        data = other.data;
    }

    threadsafe_stack& operator=(const threadsafe_stack&) = delete;

    void push(T new_value)
    {
        std::lock_guard<std::mutex> lock(m);
        data.push(std::move(new_value)); // 1
    }

    std::shared_ptr<T> pop()
    {
        std::lock_guard<std::mutex> lock(m);
        if(data.empty()) throw empty_stack(); // 2
        std::shared_ptr<T> const res(
                    std::make_shared<T>(std::move(data.top()))); // 3
        data.pop(); // 4
        return res;
    }

    void pop(T& value)
    {
        std::lock_guard<std::mutex> lock(m);
        if(data.empty()) throw empty_stack();
        value = std::move(data.top()); // 5
        data.pop(); // 6
    }

    bool empty() const
    {
        std::lock_guard<std::mutex> lock(m);
        return data.empty();
    }
};

int main()
{
    threadsafe_stack<int> a;
    a.push(5);
    int value = 0;
    a.pop(value);

    cout << value << endl;
    return 0;
}

```

这里，在empty()和pop()成员函数之间会存在潜在的竞争，不过代码会在pop()函数上锁时，显式的查询栈是否为空，所以这里的竞争是非恶性的。



#### 线程安全的队列

```c++
template<typename T>
class threadsafe_queue
{
private:
    mutable std::mutex mut;
    std::queue<T> data_queue;
    std::condition_variable data_cond;

public:
    threadsafe_queue(){}

    void push(T new_value)
    {
        std::lock_guard<std::mutex> lk(mut);
        data_queue.push(std::move(data));
        data_cond.notify_one(); // 1
    }

    void wait_and_pop(T& value) // 2
    {
        std::unique_lock<std::mutex> lk(mut);
        data_cond.wait(lk,[this]{return !data_queue.empty();});
        value=std::move(data_queue.front());
        data_queue.pop();
    }

    std::shared_ptr<T> wait_and_pop() // 3
    {
        std::unique_lock<std::mutex> lk(mut);
        data_cond.wait(lk,[this]{return !data_queue.empty();}); // 4
        std::shared_ptr<T> res(
                    std::make_shared<T>(std::move(data_queue.front())));
        data_queue.pop();
        return res;
    }

    bool try_pop(T& value)
    {
        std::lock_guard<std::mutex> lk(mut);
        if(data_queue.empty())
            return false;
        value=std::move(data_queue.front());
        data_queue.pop();
        return true;
    }

    std::shared_ptr<T> try_pop()
    {
        std::lock_guard<std::mutex> lk(mut);
        if(data_queue.empty())
            return std::shared_ptr<T>(); // 5
        std::shared_ptr<T> res(
                    std::make_shared<T>(std::move(data_queue.front())));
        data_queue.pop();
        return res;
    }

    bool empty() const
    {
        std::lock_guard<std::mutex> lk(mut);
        return data_queue.empty();
    }
};
```



#### 多线程快排



```c++
#include <iostream>
#include <list>
#include <stack>
#include <exception>
#include <mutex>
#include <memory>
#include <thread>
#include <future>
#include <vector>
#include <algorithm>
using namespace std;

struct empty_stack: std::exception
{
    const char* what() const throw() {
        return "empty stack!";
    }
};

template<typename T>
class threadsafe_stack
{
private:
    std::stack<T> data;
    mutable mutex m;
public:
    threadsafe_stack(){}

    threadsafe_stack(const threadsafe_stack& other)
    {
        lock_guard<mutex> lock(other.m);
        data = other.data;
    }

    threadsafe_stack& operator=(const threadsafe_stack&) = delete;

    void push(T new_value)
    {
        std::lock_guard<std::mutex> lock(m);
        data.push(std::move(new_value)); // 1
    }

    std::shared_ptr<T> pop()
    {
        std::lock_guard<std::mutex> lock(m);
        if(data.empty()) return nullptr; // 2
        std::shared_ptr<T> const res(
                    std::make_shared<T>(std::move(data.top()))); // 3
        data.pop(); // 4
        return res;
    }

    void pop(T& value)
    {
        std::lock_guard<std::mutex> lock(m);
        if(data.empty()) return nullptr;
        value = std::move(data.top()); // 5
        data.pop(); // 6
    }

    bool empty() const
    {
        std::lock_guard<std::mutex> lock(m);
        return data.empty();
    }
};

template<typename T>
struct sorter // 1
{
    struct chunk_to_sort
    {
        std::list<T> data;
        std::promise<std::list<T> > promise;
    };

    threadsafe_stack<chunk_to_sort> chunks; // 2
    std::vector<std::thread> threads; // 3
    unsigned const max_thread_count;
    std::atomic<bool> end_of_data;

    sorter():
        max_thread_count(std::thread::hardware_concurrency()-1),
        end_of_data(false)
    {
//        cout << "thread count: " << max_thread_count << endl;
    }

    ~sorter() // 4
    {
        end_of_data=true; // 5
        for(unsigned i=0;i<threads.size();++i)
        {
            threads[i].join(); // 6
        }
    }

    void try_sort_chunk()
    {
        std::shared_ptr<chunk_to_sort > chunk=chunks.pop(); // 7
        if(chunk)
        {
            sort_chunk(chunk); // 8
        }
    }

    std::list<T> do_sort(std::list<T>& chunk_data) // 9
    {
        if(chunk_data.empty())
        {
            return chunk_data;
        }

        std::list<T> result;
        result.splice(result.begin(),chunk_data,chunk_data.begin());

        T const& partition_val=*result.begin();
        typename std::list<T>::iterator divide_point= // 10
                std::partition(chunk_data.begin(),chunk_data.end(),
                               [&](T const& val){return val<partition_val;});

        chunk_to_sort new_lower_chunk;
        new_lower_chunk.data.splice(new_lower_chunk.data.end(),
                                    chunk_data,chunk_data.begin(),
                                    divide_point);

        std::future<std::list<T> > new_lower=
                new_lower_chunk.promise.get_future();
        chunks.push(std::move(new_lower_chunk)); // 11
        if(threads.size()<max_thread_count) // 12
        {
            threads.push_back(std::thread(&sorter<T>::sort_thread,this));
        }

        std::list<T> new_higher(do_sort(chunk_data));
        result.splice(result.end(),new_higher);
        while(new_lower.wait_for(std::chrono::seconds(0)) !=
              std::future_status::ready) // 13
        {
            try_sort_chunk(); // 14
        }

        result.splice(result.begin(),new_lower.get());
        return result;
    }

    void sort_chunk(std::shared_ptr<chunk_to_sort> const& chunk)
    {
        chunk->promise.set_value(do_sort(chunk->data)); // 15
    }

    void sort_thread()
    {
        while(!end_of_data) // 16
        {
            try_sort_chunk(); // 17
            std::this_thread::yield(); // 18
        }
    }
};

template<typename T>
std::list<T> parallel_quick_sort(std::list<T> input) // 19
{
    if(input.empty())
    {
        return input;
    }

    sorter<T> s;
    return s.do_sort(input); // 20
}

int main() {
    std::list<int> a = {7,3,4,5,6,2,5,9,10};
    auto res = parallel_quick_sort<int>(a);
    for(auto item : res) cout << item << " ";

    return 0;
}
```

